{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import hamming\n",
    "import itertools\n",
    "from helper.bitstring_helper import factoradic_to_permutation, segmented_sizes_for_factoradic, bitstring_to_int_list, \\\n",
    "    repair_factoradic_with_modulo, repair_factoradic_with_scaling, bits_needed_for_integer\n",
    "from helper.bitstring_helper import bitstring_to_single_int, single_int_to_factoradic, \\\n",
    "    bits_needed_for_permutation_as_int\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "\n",
    "dBlue = \"#003f6b\"\n",
    "lBlue = \"#00abda\"\n",
    "green = \"#95c11f\"\n",
    "dGreen = \"#00786b\"\n",
    "orange = \"#d53d0e\"\n",
    "yellow = \"#fdc300\"\n",
    "\n",
    "colors = [dBlue, lBlue, green, dGreen]\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "\n",
    "def encoding_a(bitstring, segment_sizes, use_gray):\n",
    "    route = bitstring_to_int_list(bitstring, segment_sizes, use_gray)\n",
    "    route = repair_factoradic_with_modulo(route)\n",
    "    return factoradic_to_permutation(route)\n",
    "\n",
    "\n",
    "def encoding_b(bitstring, segment_sizes, max_segment_sizes, use_gray):\n",
    "    route = bitstring_to_int_list(bitstring, segment_sizes, use_gray)\n",
    "    route = repair_factoradic_with_scaling(route, segment_sizes, max_segment_sizes)\n",
    "    return factoradic_to_permutation(route)\n",
    "\n",
    "\n",
    "def encoding_c(bitstring, n, use_gray):\n",
    "    route = bitstring_to_single_int(bitstring, use_gray)\n",
    "    route = single_int_to_factoradic(route, n)\n",
    "    return factoradic_to_permutation(route, False)\n",
    "\n",
    "\n",
    "def kendall_distance(perm1, perm2):\n",
    "    n = len(perm1)\n",
    "    index_map = {value: idx for idx, value in enumerate(perm2)}\n",
    "    mapped_perm1 = np.array([index_map[value] for value in perm1])\n",
    "    inversions = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if mapped_perm1[i] > mapped_perm1[j]:\n",
    "                inversions += 1\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def break_distance(perm1, perm2):\n",
    "    def get_adjacent_pairs(permutation):\n",
    "        return [(permutation[i], permutation[i + 1]) for i in range(len(permutation) - 1)]\n",
    "\n",
    "    # Get adjacent pairs for both permutations\n",
    "    pairs1 = get_adjacent_pairs(perm1)\n",
    "    pairs2 = get_adjacent_pairs(perm2)\n",
    "\n",
    "    # Reverse each pair in perm2\n",
    "    pairs2_reversed = [(b, a) for (a, b) in pairs2]\n",
    "\n",
    "    # Use set operations for faster lookups\n",
    "    set_pairs2 = set(pairs2)\n",
    "    set_pairs2_reversed = set(pairs2_reversed)\n",
    "\n",
    "    # Count common pairs\n",
    "    common_pairs = sum(1 for pair in pairs1 if pair in set_pairs2 or pair in set_pairs2_reversed)\n",
    "\n",
    "    # Calculate break distance\n",
    "    total_pairs = len(pairs1)\n",
    "    break_distance = total_pairs - common_pairs\n",
    "\n",
    "    return break_distance\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "problem_sizes = np.arange(2, 201)\n",
    "\n",
    "def plot_bit_scaling(problem_sizes, method):\n",
    "    ab_x = [np.sum(segmented_sizes_for_factoradic(n-1)) for n in problem_sizes]\n",
    "    c_x = [bits_needed_for_permutation_as_int(n)[0] for n in problem_sizes]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(problem_sizes, ab_x, label='Encoding A', color=colors[0])\n",
    "    plt.plot(problem_sizes, ab_x, label='Encoding B', color=colors[1], linestyle='dotted')\n",
    "    plt.plot(problem_sizes, c_x, label='Encoding C', color=colors[3])\n",
    "    plt.xlabel('Problem Size', fontsize=16)\n",
    "    plt.ylabel('Number of Bits Needed', fontsize=16)\n",
    "    if method in [0, 1]:\n",
    "        plt.yscale('log')\n",
    "    if method == 1:\n",
    "        plt.xscale('log')\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "    plot_bit_scaling(problem_sizes, i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compression_ratio_formula_ab(n, num_permutations):\n",
    "    \"\"\"Calculate the compression ratio based on the number of bits needed and the number of permutations for encodings A and B.\"\"\"\n",
    "    b = int(np.sum(segmented_sizes_for_factoradic(n-1)))\n",
    "    num_bitstring_states = 2 ** b\n",
    "    return num_bitstring_states / num_permutations\n",
    "\n",
    "\n",
    "def compression_ratio_formula_c(n, num_permutations):\n",
    "    \"\"\"Calculate the compression ratio based on the number of bits needed and the number of permutations for encoding C.\"\"\"\n",
    "    b = int(bits_needed_for_permutation_as_int(n)[0])\n",
    "    num_bitstring_states = 2 ** b\n",
    "    return num_bitstring_states / num_permutations\n",
    "\n",
    "\n",
    "def plot_compression_ratio_ab(n_values, compression_ratio_ab):\n",
    "    # Plotting the results\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(n_values, compression_ratio_ab, label=\"Encoding A\",color=colors[0])\n",
    "    plt.plot(n_values, compression_ratio_ab, label=\"Encoding B\",color=colors[1], linestyle='dotted')\n",
    "    plt.xlabel('Problem Size', fontsize=16)\n",
    "    plt.ylabel('Redundancy Ratio', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, max(n_values))\n",
    "    plt.ylim(1, max(compression_ratio_ab))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_compression_ratio_c(n_values, compression_ratios_c):\n",
    "    # Plotting the results\n",
    "    plt.figure(figsize=(10, 7), dpi=200)\n",
    "    plt.plot(n_values, compression_ratios_c, label=\"Encoding C\", color=colors[3])\n",
    "    plt.xlabel('Problem Size', fontsize=16)\n",
    "    plt.ylabel('Redundancy Ratio', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.axhline(y=1, color=orange, linestyle='--', linewidth=1)\n",
    "    plt.axhline(y=2, color=orange, linestyle='--', linewidth=1)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.xlim(0, max(n_values))\n",
    "    plt.ylim(0.85, 2.15)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "n_values = range(2, 201)\n",
    "compression_ratios_ab = []\n",
    "compression_ratios_c = []\n",
    "compression_ratios_d = []\n",
    "\n",
    "for n in n_values:\n",
    "    num_permutations = int(math.factorial(n))\n",
    "    compression_ratios_ab.append(compression_ratio_formula_ab(n, num_permutations))\n",
    "    compression_ratios_c.append(compression_ratio_formula_c(n, num_permutations))\n",
    "    # print(n, compression_ratios_ab[-1], compression_ratios_c[-1], compression_ratios_d[-1])\n",
    "\n",
    "plot_compression_ratio_ab(n_values, compression_ratios_ab)\n",
    "plot_compression_ratio_c(n_values, compression_ratios_c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 5\n",
    "factor_segment_sizes = segmented_sizes_for_factoradic(n-1)\n",
    "bitstrings_ab = [np.array(bits) for bits in itertools.product([0, 1], repeat=np.sum(factor_segment_sizes))]\n",
    "max_segment_sizes = np.arange(n - 1, 0, -1)\n",
    "bitstrings_c = [np.array(bits) for bits in itertools.product([0, 1], repeat=bits_needed_for_permutation_as_int(n)[0])]\n",
    "d1_segmented_sizes = [bits_needed_for_integer(1)]*n\n",
    "d3_segmented_sizes = [bits_needed_for_integer(3)]*n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mutate_bitstring(bitstring, index):\n",
    "    \"\"\"Flip a single bit in the bitstring at the specified index, then revert it after mutation.\"\"\"\n",
    "    bitstring[index] = 1 - bitstring[index]  # Flip the bit\n",
    "    return bitstring\n",
    "\n",
    "\n",
    "def mutation_impact_analysis(encoding_fn, bitstrings, distance_meas, *encoding_args):\n",
    "    \"\"\"Analyze the impact of a single-bit mutation on the resulting permutation with optimizations.\"\"\"\n",
    "    impacts = np.zeros((len(bitstrings), len(bitstrings[0])))  # Initialize a 2D array for impacts\n",
    "\n",
    "    for bit_idx, bitstring in enumerate(bitstrings):\n",
    "        original_permutation = encoding_fn(bitstring, *encoding_args)\n",
    "        for i in range(len(bitstring)):\n",
    "            mutated_bitstring = mutate_bitstring(bitstring.copy(), i)\n",
    "            mutated_permutation = encoding_fn(mutated_bitstring, *encoding_args)\n",
    "            result = distance_meas(original_permutation, mutated_permutation)\n",
    "            impacts[bit_idx, i] = result if not isinstance(result, tuple) else result[0]\n",
    "            # print(result, original_permutation, mutated_permutation)\n",
    "    return impacts\n",
    "\n",
    "\n",
    "def plot_mutation(hist_data_dict, dist_name):\n",
    "    all_data = np.concatenate([data.flatten() for data in hist_data_dict.values()])\n",
    "    min_val, max_val = all_data.min(), all_data.max()\n",
    "    bins = np.arange(min_val, max_val + 2) - 0.5\n",
    "\n",
    "    # Creating grouped bar chart data\n",
    "    bin_labels = np.arange(min_val, max_val + 1)\n",
    "    width = 0.3  # Width of each bar\n",
    "    offsets = np.arange(-(len(hist_data_dict) - 1) / 2, (len(hist_data_dict) + 1) / 2) * width\n",
    "\n",
    "    for i, (label, data) in enumerate(hist_data_dict.items()):\n",
    "        counts, _ = np.histogram(data.flatten(), bins=bins)\n",
    "        plt.bar(bin_labels + offsets[i], counts, width=width, alpha=0.8, label=label, color=colors[i])\n",
    "\n",
    "    plt.xlabel(dist_name, fontsize=16)\n",
    "    plt.ylabel('Count', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.xticks(bin_labels)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dists = {\n",
    "    'Hamming Distance': lambda x, y: hamming(x, y) * len(x),\n",
    "    'Kendall \\u03C4 Distance': kendall_distance,\n",
    "    'Break Distance': break_distance,\n",
    "    'Levenshtein Distance': levenshtein_distance,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "def save_mutation_data(hist_data_dict):\n",
    "    mutation_count_data = defaultdict(lambda: defaultdict(int))  # Nested defaultdict for storing counts\n",
    "\n",
    "    for encoding_type, data in hist_data_dict.items():\n",
    "        flattened_data = data.flatten()\n",
    "        unique, counts = np.unique(flattened_data, return_counts=True)\n",
    "        for dist_val, count in zip(unique, counts):\n",
    "            mutation_count_data[encoding_type][dist_val] += count\n",
    "\n",
    "    return mutation_count_data\n",
    "\n",
    "\n",
    "mutation_results = defaultdict(dict)\n",
    "mutation_results_gray = defaultdict(dict)\n",
    "for dist_name, distance_meas in dists.items():\n",
    "    impacts_a = mutation_impact_analysis(encoding_a, bitstrings_ab, distance_meas, factor_segment_sizes, False)\n",
    "    impacts_b = mutation_impact_analysis(encoding_b, bitstrings_ab, distance_meas, factor_segment_sizes, max_segment_sizes,\n",
    "                                         False)\n",
    "    impacts_c = mutation_impact_analysis(encoding_c, bitstrings_c, distance_meas, n, False)\n",
    "\n",
    "    impacts_ag = mutation_impact_analysis(encoding_a, bitstrings_ab, distance_meas, factor_segment_sizes, True)\n",
    "    impacts_bg = mutation_impact_analysis(encoding_b, bitstrings_ab, distance_meas, factor_segment_sizes, max_segment_sizes,\n",
    "                                          True)\n",
    "    impacts_cg = mutation_impact_analysis(encoding_c, bitstrings_c, distance_meas, n, True)\n",
    "\n",
    "    mutation_data = {'Encoding A': impacts_a, 'Encoding B': impacts_b, 'Encoding C': impacts_c}\n",
    "    mutation_data_gray = {'Encoding AG': impacts_ag, 'Encoding BG': impacts_bg, 'Encoding CG': impacts_cg}\n",
    "\n",
    "    plot_mutation(mutation_data, dist_name)\n",
    "    plot_mutation(mutation_data_gray, dist_name)\n",
    "    mutation_results[dist_name] = save_mutation_data(mutation_data)\n",
    "    mutation_results_gray[dist_name] = save_mutation_data(mutation_data_gray)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 5\n",
    "segment_sizes = segmented_sizes_for_factoradic(n-1)\n",
    "bitstrings_ab = [np.array(bits, dtype=object) for bits in itertools.product([0, 1], repeat=sum(segment_sizes)) ]\n",
    "\n",
    "max_segment_sizes = np.arange(n - 1, 0, -1)\n",
    "bitstrings_c = [np.array(bits, dtype=object) for bits in itertools.product([0, 1], repeat=bits_needed_for_permutation_as_int(n)[0])]\n",
    "\n",
    "def plot_permutation_histograms(n, bitstrings_ab, bitstrings_c, encoding_a, encoding_b, encoding_c, colors, segment_sizes, max_segment_sizes):\n",
    "    # Collect the permutation counts for each encoding\n",
    "    all_permutations_a = [tuple(encoding_a(bitstring, segment_sizes, False)) for bitstring in bitstrings_ab]\n",
    "    all_permutations_b = [tuple(encoding_b(bitstring, segment_sizes, max_segment_sizes, False)) for bitstring in bitstrings_ab]\n",
    "    all_permutations_c = [tuple(encoding_c(bitstring, n, False)) for bitstring in bitstrings_c]\n",
    "    #\n",
    "    # Count the occurrences of each permutation for each encoding\n",
    "    permutation_counts_a = Counter(all_permutations_a)\n",
    "    permutation_counts_b = Counter(all_permutations_b)\n",
    "    permutation_counts_c = Counter(all_permutations_c)\n",
    "    print(max(permutation_counts_a.values()))\n",
    "\n",
    "    # Sort the permutations to maintain the same order across all plots\n",
    "    all_permutations = sorted(set(permutation_counts_a.keys()).union(permutation_counts_b.keys(), permutation_counts_c.keys()))\n",
    "\n",
    "    # Align counts with the sorted permutations\n",
    "    counts_a = [permutation_counts_a.get(p, 0) for p in all_permutations]\n",
    "    counts_b = [permutation_counts_b.get(p, 0) for p in all_permutations]\n",
    "    counts_c = [permutation_counts_c.get(p, 0) for p in all_permutations]\n",
    "\n",
    "    # Plot the histograms in subplots\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True, gridspec_kw={'hspace': 0})  # Increase the figure size\n",
    "    labels = [str(p) for p in all_permutations]\n",
    "\n",
    "\n",
    "    # Plot each histogram\n",
    "    axes[0].bar(range(len(all_permutations)), counts_a, color=colors[0], label='Encoding A')\n",
    "    axes[1].bar(range(len(all_permutations)), counts_b, color=colors[1], label='Encoding B')\n",
    "    axes[2].bar(range(len(all_permutations)), counts_c, color=colors[3], label='Encoding C')\n",
    "\n",
    "    # Set labels, titles, and y-axis ticks for each subplot\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.set_ylabel('Counts', labelpad=10, fontsize=13)  # Add padding to the y-axis label\n",
    "        max_count = max([counts_a, counts_b, counts_c][i])\n",
    "        ax.set_yticks(range(0, max_count + 1))  # Set y-ticks as integers\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.set_xlim(left=-1, right=len(all_permutations))\n",
    "\n",
    "    # Configure x-axis for the bottom plot\n",
    "    axes[2].set_xticks(range(len(all_permutations)))\n",
    "    axes[2].set_xticklabels(labels, rotation=90, ha='right', fontsize=9)\n",
    "    axes[2].set_xlabel('Permutations', fontsize=13)\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout(pad=2.0)  # Add extra padding to prevent y-axis tick overlap\n",
    "    plt.subplots_adjust(bottom=0.25)  # Add space at the bottom for x-axis labels\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with the provided parameters\n",
    "plot_permutation_histograms(n, bitstrings_ab, bitstrings_c, encoding_a, encoding_b, encoding_c, colors, segment_sizes, max_segment_sizes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_max_redundancy(n_values, encoding_a, colors):\n",
    "    max_counts = []\n",
    "\n",
    "    for n in n_values:\n",
    "        segment_sizes = segmented_sizes_for_factoradic(n - 1)\n",
    "        bitstrings_ab = [np.array(bits, dtype=object) for bits in itertools.product([0, 1], repeat=sum(segment_sizes))]\n",
    "        all_permutations_a = [tuple(encoding_a(bitstring, segment_sizes, False)) for bitstring in bitstrings_ab]\n",
    "        permutation_counts_a = Counter(all_permutations_a)\n",
    "\n",
    "        # Get the maximum count of any permutation\n",
    "        max_count = max(permutation_counts_a.values())\n",
    "        max_counts.append(max_count)\n",
    "        print(n, np.sum(segment_sizes), max_count)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(n_values, max_counts, marker='o', color=colors[0], label='Maximum Redundancy')\n",
    "    plt.xlabel('Problem Size')\n",
    "    plt.ylabel('Maximum Redundancy of a Single Permutation')\n",
    "    plt.xticks(n_values)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "n_values = range(2, 10)\n",
    "plot_max_redundancy(n_values, encoding_a, colors)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mutation_impact_analysis_on_int(bitstrings, gray):\n",
    "    \"\"\"Analyze the impact of a single-bit mutation on the resulting permutation with optimizations.\"\"\"\n",
    "    impacts = np.zeros((len(bitstrings), len(bitstrings[0])))  # Initialize a 2D array for impacts\n",
    "\n",
    "    for bit_idx, bitstring in enumerate(bitstrings):\n",
    "        original = bitstring_to_single_int(bitstring, gray)\n",
    "        for i in range(len(bitstring)):\n",
    "            mutated_bitstring = mutate_bitstring(bitstring.copy(), i)\n",
    "            mutated = bitstring_to_single_int(mutated_bitstring, gray)\n",
    "            # print(gray, bitstring, mutated_bitstring, original, mutated, abs(original - mutated))\n",
    "            result = abs(original - mutated)\n",
    "            impacts[bit_idx, i] = result if not isinstance(result, tuple) else result[0]\n",
    "    return impacts\n",
    "\n",
    "\n",
    "data = {\"Encoding C\": mutation_impact_analysis_on_int(bitstrings_c, False),\n",
    "        \"Encoding CG\": mutation_impact_analysis_on_int(bitstrings_c, True)}\n",
    "\n",
    "\n",
    "def plot(data):\n",
    "    plt.figure(figsize=(8, 6))  # Adjust the figure size as needed\n",
    "    for (label, values), color in zip(data.items(), colors[-2:]):\n",
    "        counts, bin_edges = np.histogram(values.flatten(), bins=128)\n",
    "        plt.bar(bin_edges[:-1], counts, width=1, alpha=0.8, color=color, label=label)  #np.diff(bin_edges)\n",
    "    plt.xlabel('Distance', fontsize=16)\n",
    "    plt.ylabel('Counts', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlim(left=0)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def plot_cum(data):\n",
    "    # Plotting the cumulative distribution of mutation impacts\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    for idx, (encoding, impacts) in enumerate(data.items()):\n",
    "        flat_impacts = impacts.flatten()\n",
    "        sorted_impacts = np.sort(flat_impacts)\n",
    "        cumulative_percent = np.cumsum(sorted_impacts) / np.sum(sorted_impacts) * 100\n",
    "        # Use the corresponding color from the list, defaulting if the list is too short\n",
    "        ax.plot(sorted_impacts, cumulative_percent, label=encoding, color=colors[-2:][idx])\n",
    "\n",
    "    ax.set_xlabel('Distance', fontsize=14)\n",
    "    ax.set_ylabel('Cumulative Percentage (%)',  fontsize=14)\n",
    "    ax.legend(fontsize=12)\n",
    "    plt.xlim(left=0)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot(data)\n",
    "plot_cum(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_cumulative_counts(data):\n",
    "    \"\"\"Calculate and print the cumulative sum of counts at specified distances.\"\"\"\n",
    "    distances = [1, 2, 4, 8, 16, 32, 64]  # The specific distances to consider\n",
    "\n",
    "    for encoding, impacts in data.items():\n",
    "        print(f\"\\nEncoding: {encoding}\")\n",
    "        flat_impacts = impacts.flatten()\n",
    "\n",
    "        # Calculate the histogram\n",
    "        counts, bin_edges = np.histogram(flat_impacts, bins=128)\n",
    "\n",
    "        # Calculate the cumulative sum of counts\n",
    "        cumulative_counts = np.cumsum(counts)\n",
    "        total_counts = cumulative_counts[-1]  # The total number of counts\n",
    "\n",
    "        # Find cumulative counts at the specified distances\n",
    "        for distance in distances:\n",
    "            # Find the bin index closest to the current distance\n",
    "            bin_index = np.searchsorted(bin_edges, distance, side='right') - 1\n",
    "            if bin_index < 0 or bin_index >= len(cumulative_counts):\n",
    "                print(f\"Distance {distance}: Out of bounds\")\n",
    "                continue\n",
    "\n",
    "            cumulative_percentage = cumulative_counts[bin_index] / total_counts * 100\n",
    "            print(f\"Distance {distance}: Cumulative Percentage = {cumulative_percentage:.2f}%\")\n",
    "\n",
    "print_cumulative_counts(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class VehicleRoutingProblem:\n",
    "    def __init__(self, filename: str):\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "        self.distance_matrix = None\n",
    "        self.length = 0\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        # Load data from the file\n",
    "        # The 'data' attribute is assumed to be structured as [[x, y, demand], ...] including the depot\n",
    "        # Here we're simulating loading data (in practice you'd load from a file)\n",
    "        self.data = np.array([[0, 0, 0],  # Depot\n",
    "                              [10, 10, 5],  # Customer 1\n",
    "                              [20, 20, 10],  # Customer 2\n",
    "                              [30, 30, 15]])  # Customer 3\n",
    "\n",
    "        # Compute distance matrix based on coordinates (x, y)\n",
    "        self.distance_matrix = self.compute_distance_matrix(self.data)\n",
    "        self.length = len(self.data)  # Number of locations (including depot)\n",
    "\n",
    "    def compute_distance_matrix(self, data):\n",
    "        \"\"\"\n",
    "        Computes a distance matrix between all points (including the depot).\n",
    "        \"\"\"\n",
    "        n = len(data)\n",
    "        dist_matrix = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                dist_matrix[i][j] = np.sqrt((data[i][0] - data[j][0]) ** 2 + (data[i][1] - data[j][1]) ** 2)\n",
    "        return dist_matrix\n",
    "\n",
    "def split_route(vrp: VehicleRoutingProblem, global_route, vehicle_capacity):\n",
    "    \"\"\"\n",
    "    Splits a given global route into feasible routes based on vehicle capacity.\n",
    "\n",
    "    Args:\n",
    "        vrp: The VehicleRoutingProblem instance with data and distance matrix.\n",
    "        global_route: List of customer indices representing the global route (without depot).\n",
    "        vehicle_capacity: The capacity of the vehicle.\n",
    "\n",
    "    Returns:\n",
    "        predecessor_list: List of predecessors for route reconstruction.\n",
    "        min_cost: List of minimum costs to reach each customer.\n",
    "    \"\"\"\n",
    "    num_customers = len(global_route)  # Number of customers in the route\n",
    "    min_cost = [float('inf')] * (num_customers + 1)  # Minimum cost to reach each customer\n",
    "    predecessor_list = [None] * (num_customers + 1)  # List of predecessors for optimal route reconstruction\n",
    "    min_cost[0] = 0  # Start at the depot, cost to reach depot is 0\n",
    "\n",
    "    # Loop through each customer `i` in the sequence\n",
    "    for i in range(1, num_customers + 1):\n",
    "        total_demand = 0\n",
    "        j = i\n",
    "        while j <= num_customers and total_demand + vrp.data[global_route[j-1], 2] <= vehicle_capacity:\n",
    "            total_demand += vrp.data[global_route[j-1], 2]\n",
    "            # Calculate the cost of the route segment from customer i to j\n",
    "            if j == i:\n",
    "                # If it's a single customer, cost is depot -> customer -> depot\n",
    "                trip_cost = (vrp.distance_matrix[0][global_route[i-1]]  # Depot -> customer i\n",
    "                             + vrp.distance_matrix[global_route[i-1]][0])  # Customer i -> depot\n",
    "            else:\n",
    "                # For multiple customers, calculate the trip cost\n",
    "                trip_cost = (vrp.distance_matrix[0][global_route[i-1]]  # Depot -> first customer in the segment\n",
    "                             + sum(vrp.distance_matrix[global_route[k-1]][global_route[k]] for k in range(i, j-1))  # Customer chain\n",
    "                             + vrp.distance_matrix[global_route[j-1]][0])  # Last customer -> depot\n",
    "\n",
    "            # Update minimum cost and predecessor if a better path is found\n",
    "            if min_cost[i-1] + trip_cost < min_cost[j]:\n",
    "                min_cost[j] = min_cost[i-1] + trip_cost\n",
    "                predecessor_list[j] = i-1\n",
    "\n",
    "            j += 1\n",
    "\n",
    "    # Return predecessor list and minimum costs\n",
    "    return predecessor_list, min_cost\n",
    "\n",
    "def extract_routes(global_route, predecessor_list):\n",
    "    \"\"\"\n",
    "    Extracts the optimal routes from the predecessor list.\n",
    "\n",
    "    Args:\n",
    "        global_route: List of customer indices representing the global route (without depot).\n",
    "        predecessor_list: Predecessor list returned by the split method.\n",
    "\n",
    "    Returns:\n",
    "        routes: A list of routes, where each route is a list of customer indices starting and ending with the depot.\n",
    "    \"\"\"\n",
    "    routes = []\n",
    "    current_index = len(global_route)  # Start from the last customer\n",
    "    while current_index > 0:\n",
    "        previous_index = predecessor_list[current_index]\n",
    "        # Extract the customers between previous_index and current_index\n",
    "        route_segment = global_route[previous_index:current_index]\n",
    "        # Add the depot at the start and end of the route\n",
    "        route = [0] + route_segment + [0]\n",
    "        routes.append(route)\n",
    "        # Move to the predecessor\n",
    "        current_index = previous_index\n",
    "\n",
    "    # Reverse routes to get them in correct order\n",
    "    return routes[::-1]  # Since routes are constructed backwards\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Create the VRP instance\n",
    "    vrp = VehicleRoutingProblem('dummy_file.txt')\n",
    "\n",
    "    # Customer sequence (global route without depot)\n",
    "    global_route = [1, 2, 3]\n",
    "\n",
    "    # Perform split based on vehicle capacity\n",
    "    vehicle_capacity = 20\n",
    "    predecessor_list, min_cost = split_route(vrp, global_route, vehicle_capacity)\n",
    "\n",
    "\n",
    "    # Extract routes from predecessors\n",
    "    routes = extract_routes(global_route, predecessor_list)\n",
    "\n",
    "    # Print the routes and total cost\n",
    "    print(\"Optimal Routes:\", routes)\n",
    "    print(\"Minimum Cost to Reach Each Customer:\", min_cost)\n",
    "    print(\"Total Cost of the Solution:\", min_cost[-1])  # Total cost is the cost to reach the last customer\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
